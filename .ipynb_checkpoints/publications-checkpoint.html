<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Kun Ding; 丁昆; Computer Vision; Deep Learning; Multimedia; Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS); Institute of Automation; Chinese Academy of Sciences">
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.min.js"></script>
<link rel="author" href="https://kding1225.github.io/">

    <title>Kun Ding - Publications</title>
    <style>

@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : rgb(224, 224, 224); }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
.container_title { width : 750px; margin : 20px auto; border-radius: 10px;  padding : 20px;  clear:both;}
.iframe_video {float: left; margin-right: 30px}
#bio {
    padding-top : 20px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; margin-right : 100px; border : 0 solid black; float : left; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="./homepage_files/analytics.js"></script>
</head>

<body>

    <div class="container" style="text-align: center;">
        <h2 style="margin: 0; font-family: 'Segoe UI', Arial, sans-serif; font-size: 1.5em; font-weight: 500;">
            Home
            <span style="color: #ccc; font-size: 1.3em;"> • </span>
            Publications
            <span style="color: #ccc; font-size: 1.3em;"> • </span>
            CV
        </h2>
    </div>

	<div class="container">
	<h2>Publications <small><a href="https://scholar.google.com/citations?user=kbwv2tkAAAAJ">[Google Scholar]</a></small> </h2>
        <br>
        <h3>2025</h3>
        <div class="publication">
            <img src="./homepage_files/agent_reviewer.png" class="publogo" width="250 px">
            <p>
                <strong>
                    <a href="https://github.com/AReviewers/AgentReviewers">Agent Reviewers: Domain-specific Multimodal Agents with Shared Memory for Paper Review</a>
                </strong>
                <br>
                Kai Lu, Shixiong Xu, Jinqiu Li, Kun Ding, Gaofeng Meng.
                <br>
                <em>International Conference on Machine Learning (ICML), 2025</em>
                <br>
                <span class="links">
                    <a href="https://icml.cc/virtual/2025/poster/43850">PDF</a>
                    <a href="https://github.com/AReviewers/AgentReviewers">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/RCTS.png" class="publogo" width="250 px">
            <p>
                <strong>
                    <a href="https://icml.cc/virtual/2025/poster/46017">Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger</a>
                </strong>
                <br>
                Qi Yang, Chenghao Zhang, Lubin Fan, Kun Ding, Jieping Ye, Shiming Xiang.
                <br>
                <em>International Conference on Machine Learning (ICML), 2025</em>
                <br>
                <span class="links">
                    <a href="https://icml.cc/virtual/2025/poster/46017">PDF</a>
                    <a href="https://github.com/yannqi/RCTS-RAG">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/UNIP.png" class="publogo" width="250 px">
            <p>
                <strong>
                    <a href="https://arxiv.org/abs/2502.02257">UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation</a>
                </strong>
                <br>
                Tao Zhang, Jinyong Wen, Zhen Chen, Kun Ding, Shiming Xiang, Chunhong Pan.
                <br>
                <em>International Conference on Learning Representations (ICLR), 2025</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2502.02257">PDF</a>
                    <a href="https://github.com/casiatao/UNIP">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/CLIPMoA.png" class="publogo" width="250 px">
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/10980215">CLIP-MoA: Visual-Language Models with Mixture of Adapters for Multi-task Remote Sensing Image Classification</a>
                </strong>
                <br>
                <br>
                Zhongzheng Fu, Hongping Yan, Kun Ding.
                <br>
                <em>IEEE Transactions on Geoscience and Remote Sensing (IEEE T-GRS), 2025</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/10980215">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2024</h3>
        <div class="publication">
            <img src="./homepage_files/VLPTOOD.png" class="publogo" width="250 px">
            <p>
                <strong>
                    <a href="https://github.com/kding1225/VLPT-OOD">Weak Distribution Detectors Lead to Stronger Generalizability of Vision-language Prompt Tuning</a>
                </strong>
                <br>
                <br>
                Kun Ding, Haojian Zhang, Qiang Yu, Ying Wang, Shiming Xiang, Chunhong Pan.
                <br>
                <em>Association for the Advancement of Artificial Intelligence (AAAI), 2024</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2404.00603">PDF</a>
                    <a href="https://github.com/kding1225/VLPT-OOD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/ZiRaGroundingDINO.png" class="publogo" width="250 px">
            <p> 
                <strong>
                    <a href="https://github.com/JarintotionDin/ZiRaGroundingDINO">Zero-shot Generalizable Incremental Learning for Vision-Language Object Detection</a>
                </strong>
                <br>
                <br>
                Jieren Deng, Haojian Zhang, Kun Ding, Jianhua Hu, Xingxuan Zhang, Yunkuan Wang.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2024</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2403.01680">PDF</a>
                    <a href="https://github.com/JarintotionDin/ZiRaGroundingDINO">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/Smalnet.png" class="publogo" width="250 px">
            <p>
                <strong>
                    <a href="https://www.sciencedirect.com/science/article/pii/S1350449524004249">Smalnet: Segment Anything Model Aided Lightweight Network for Infrared Image Segmentation</a>
                </strong>
                <br>
                <br>
                Kun Ding, Shiming Xiang, Chunhong Pan.
                <br>
                <em>Infrared Physics & Technology, 2024</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.sciencedirect.com/science/article/pii/S1350449524004249">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2020 and before</h3>
        <div class="publication">
            <img src="./homepage_files/packdet.png" class="publogo" width="250 px">
            <p> 
                <strong>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-58601-0_11">PackDet: Packed Long-Head Object Detector</a>
                </strong>
                <br>
                <br>
                Kun Ding, Guojin He, Huxiang Gu, Zisha Zhong, Shiming Xiang, Chunhong Pan.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-58601-0_11">PDF</a>
                    <a href="https://github.com/kding1225/PackDet">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
    </div>

</body></html>
